\documentclass[../main.tex]{subfiles}
\usepackage{amsmath, bm}
\begin{document}

\noindent
본 챕터에서는 지금까지의 챕터에서 설명한 각종 기법을 취합하여 대어휘 연속 음성 인식 (large vocabulary continuous speech recognition; LVCSR) 엔진을 구성하는 방법에 대해 설명한다. 

\section{FST의 합성과 확률모델}
지금까지 도입했던 음성인인식의 요소를 나타내는 FST를 합성하고, 합성한 FST의 최단 경로 문제의 풀이로서 음성인식결과를 얻는 방법을 고찰한다. 음성인식의 통계모델을 표현하는 FST는 일반적으로는 아래의 4 종류가 있다. 

\begin{itemize}
    \item \textbf{\textit{G}}: 단어열 Acceptor (\hyperref[sec:N-gram-FST]{6.5})
    \item \textbf{\textit{L}}: 문맥에 의존하지 않는 음소열로부터 단어열 변환 (\hyperref[subsec:pronunciation-model]{4.2.2})
    \item \textbf{\textit{C}}: 문맥에 의존하는 음소열로부터 문맥에 의존하지 않는 음소열로 변환 (\hyperref[sec:context-dependant-model]{5.3})
    \item \textbf{\textit{H}}: HMM state 시퀀스로부터 문맥에 의존하는 음소열로 변환 (\hyperref[sec:context-dependant-model]{5.3})
\end{itemize}
여기에 덧붙여서, 이하의 식에서 보여지고 있는 입력 (관측 벡터열)과 HMM 상태변수의 관계를 나타내는 FST \textbf{\textit{E}}를 가상으로 도입함으로써, 인식할 때의 처리를 모두 FST 형식으로 기술할 수 있게 된다. 

\begin{equation}\label{eq:7-1}
    \begin{split}
    Q[\bm{E}] &= \{0,\ldots,T\}, \qquad I[\bm{E}] = \{(0,\overline{1})\}, \qquad F[\bm{E}] = \{(T,\overline{1})\}, \\
    E[\bm{E}] &= \{(t-1, t, \sigma, \sigma, -\log p(\mathbf{x_t} | s_t = \sigma)): t \in {1, \ldots, T}, \sigma \in \Sigma[\bm{H}] \}
    \end{split}
\end{equation}

여기에서 \textit{T}는 관측 벡터열의 길이를 의미한다. 

\subsection{디코딩 네트워크의 구성과 탐색오류}
\subsection{disambiguation 심볼}

\section{대어휘 연속 음성인식의 탐색문제}

\section{대규모 FST 합성 기술}
\subsection{온 더 플라이 합성}
\subsection{디스크 기반 인식 시스템}

\section{N-Best 리스트 및 lattice 생성}
\subsection{lattice 생성}
\subsection{lattice로부터 N-Best 리스트 생성}

\section*{인용 및 참고문헌}

\end{document}
